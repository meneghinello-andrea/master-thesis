%---------------------------------------------------------------------------------------------------
%		requirements.tex
%
%	This is the main file of the chapter that talk about elasticity.
%
%	Author: Andrea Meneghinello
% Version: 0.1
%	Table of changes:
%		17/03/2016 -> document definition
%---------------------------------------------------------------------------------------------------
\section{Requirements}
\label{sec:elasticity-requirements}
\citeauthor{herbst2013elasticity} in \cite{herbst2013elasticity} define elasticity in cloud computing
model as:

\begin{quote}
	``the degree to which a system is able to adapt to workload changes by provisioning and
	deprovisioning resources in an automatic manner, such that at each point in time the available resources
	match the current demand as closely as possible.''
\end{quote}

The given definition states that elasticity is basically the combination of two complementary
dimensions: \keyword{scalability} and \keyword{adaptivity}. Therefore elastic services (or applications)
should be able to collect new computing resources when their workload is increased, but also to discard
any exceeding resources when such workload decreases. Additionally, such resource management should be
the most autonomous as possible; e.g. driven by the system itself without any human operator or
administrator interference.

From \citeauthor{herbst2013elasticity} definition of elasticity, some requirements may be
identified: \keyword{autonomy}, \keyword{scalability} and \keyword{adaptability}.

Those are general requirements that have to be considered in any kind of elastic service or application,
but we are interested on the \ac{paas} cloud computing service model so other requirements arise;
they are: \keyword{\ac{sla}-awareness}, \keyword{composability} and finally \keyword{service continuity
in software upgrades}.

In the following sections we will cover in deep all these requirements giving its definition and
some explanations for each one.

\subsection{Autonomy}
\label{sec:elasticity-requirements-autonomy}
Platforms being provided in \ac{paas} service model should deal itself (ideally without any human
interaction) with the elastic behaviour of the services deployed by its customers.

In order to have an autonomic behaviour, an application or service should be carefully designed. In 
\cite{ibm2005architectural} a system is considered autonomic when it is able to self-manage with a
minimum of human interference. In that case, such software elements should be self-configuring,
self-healing, self-optimising and finally self-protecting. To this end, a set of autonomic software
components should be controlled by an autonomic manager, which is governed by a major-loop
composed by four different stages (shown in Figure \ref{img:elasticity-requirements-autonomy}):

\begin{enumerate}
	\item{\keyword{monitor}: in this stage some information is collected by sensors on each managed
		element. These data are then filtered and aggregated in order to build a coherent response. The
		data being considered consist of multiple metrics ad descriptions of the current resource
		topology;}
	\item{\keyword{analyse}: the data coming from the previous stage are correlated in order to consider
		some behavioural models; this allows the autonomic manager to learn from the environment and helps
		to predict future situations for the managed elements;}
	\item{\keyword{plan}: considers the information provided by the previous stage, and decides the
		actions to be performed in order to reach the system goals, according to existing policies;}
	\item{\keyword{execute}: finally autonomic manager applies those actions to the managed elements
		though the corresponding effectors.}
\end{enumerate}

Each stage is continuously being applied and its output is considered by the next step in the control
loop. To this end, the stages may access to a shared \keyword{knowledge base} where global policies
can be found and interesting information can be generated in each stage. In most cases, such data
needs to be considered in the first two stages.

\begin{figure}
	\centering{}
	\includegraphics[width=0.4\textwidth]{chapters/elasticity/images/autonomy.png}
	\caption[Major-loop for autonomy]{Major-loop to implement the autonomy requirement.}
	\label{img:elasticity-requirements-autonomy}
\end{figure}

This general picture of autonomic computing can be easily tailored for cloud computing systems that
follows the \ac{paas} service model. Through autonomic manager we want to reach a combination of:

\begin{itemize}
	\item{a general economic goal on which we want to minimize the cost of the underlying infrastructure,
		which is required to support all the software deployed on the platform; and}
	\item{a specific set of rules, that depends on each customer applications deployed (\ac{sla}).}
\end{itemize}

\subsection{Scalability}
\label{sec:elasticity-requirements-scalability}
In order to have an elastic system the software services it provides should be \keyword{scalable}. This
means that when incoming workload is increased, the capacity of the serving nodes should be also
enlarged. There are different scalability systems: \keyword{replication}, \keyword{redimensioning} and
finally \keyword{migration}.

Replication or scaling horizontally means adding (or removing) nodes in a system, for executing additional
server instances when such serving capacity needs to be increased (or decreased). This may be implemented
adding new \ac{vm}s to the current set, deploying there some instances of the required service components.
Replication is a mechanism used also to achieve service availability. Two classical replication models
exists: \keyword{active-replication} on which every client request is forwarded to all the server replicas,
and every one executes directly each requests; and \keyword{passive-replication} on which every client request
is sent to a special replica that serves each request and forwards any state updates to the remaining replicas.
Replication was already used before cloud computing became available. In many cases applications have adopted
low-cost commodity systems to execute tasks that once required supercomputer, because computer prices have
dropped and performance continues to increase. In addiction the development of high-performance networks,
such as Gigabit Ethernet, powered this scalability model. In this model we refer with the term
\keyword{scale-out} when we are adding new nodes in the cluster, instead with \keyword{scale-in} the opposite
scenario (when nodes are removed).

Redemensioning or scaling vertically means adding (or removing) resources to a single node in the system,
typically involving the addition (or removal) of \acs{cpu}s, memory or network capabilities. Unfortunately,
many \ac{iaas} providers do not allow \ac{vm} redimensioning at run-time. Note that this procedure requires
that either the host has free resources at redimensioning time or the other guest \ac{vm}s should also adapt
their provisioned set of resources to accommodate such redimensioning. Instead of those dynamic redimensioning
actions, most \ac{iaas} providers facilitate a static set of \ac{vm} types and the consumer is compelled 
to select which kind of \ac{vm} should be used in each image allocation. In this model we refer with the term
\keyword{scale-up} when we are adding new resources to a node, instead with term \keyword{scale-down} the
opposite scenario.

\begin{figure}
	\centering{}
	\includegraphics[width=0.6\textwidth]{chapters/elasticity/images/horizontal-vs-vertical-scaling.png}
	\caption[Difference between horizontal and vertical scalability]{The image shows the difference between
		horizontal and vertical scalability. Reading it in a bottom-up way we have respectively scale scale-up
		and scale-out. Instead, reading it in a top-down way we have respectively scale-down and scale-in.}
	\label{img:solutionSpace-elasticity-availableTypes}
\end{figure}

When the underlying infrastructure does not allow \ac{vm} redimensioning, vertical scalability may be
implemented migrating the \ac{vm} instances from their current server to another more powerful one.
Depending on the size of the instance image, the network bandwidth and the location of
the host computers, migration may need a long time to be concluded (several seconds). Migration is a
three step procedure:

\begin{itemize}
	\item{the current instance image should be stopped. Such stop action should be initiated when such
		instance is not serving any request (e.g. when it remains in idle waiting for a new request);}
	\item{its image should be transferred to the new location;}
	\item{its activity should be restarted in the new location\footnote{If the instance identity and
		network should be preserved, some routing reconfiguration will be needed in this step.}.}
\end{itemize}

However, using \ac{paas} cloud model as a base to build our services or applications leads us to consider
only the horizontal scalability type since we are not able to manifest our preferences in term of hardware
that must be available under our services or applications. Hence our purpose in the remaining part of the
thesis is finding an application design model that is able to take advantage of the elasticity
provided by the cloud.

\subsection{Adaptability}
\label{sec:elasticity-requirements-adaptability}
In elasticity we refer to adaptivity as the possibility to ``optimally'' adjusting the computing capacity
of a given service to the current workload, at run-time. So, besides being scalable, an elastic service
should also be adjustable to the workload being received at each moment.

Adaptability as two different dimensions:

\begin{enumerate}
	\item{\keyword{adaptability}: it refers to the potential for adapting a system. This means that the
		system components have been designed considering that sooner or later they will need to be
		reconfigured or restructured in some way. It is a static dimension. An elastic system should be
		both scalable and adapting, focusing that adaptability on the tools needed for guaranteeing the
		scalability \ac{qos};}
	\item{\keyword{adaptivity}: it is the system's ability to adapt itself. An adaptive system is able
		to find out when adapting actions should be applied. This means that adaptable systems become
		adaptive when they are able to provide an autonomous management. Since autonomy is one of the
		elasticity requirements, elastic systems need to be adaptive. To this end, their architecture
		should include monitoring, analysis, planning and execution subsystems that automate all
		reconfiguration-related decisions.}
\end{enumerate}

The are two main approaches for reaching adaptivity: \keyword{proactive} and \keyword{reactive}.
Figure \ref{img:elasticity-requirements-adaptability} illustrates when the different approaches
enter in action following a workload change.

In the proactive (or predictive) case, some workload analysis or workload modelling is done in order
to predict the workload levels in the near future. With this knowledge the actions needed to correctly
adapt the service capacity to current workload are taken before hand. Hence, \ac{qos} can be easily
guaranteed when those predictions have an acceptable level of accuracy.

On the other hand, with a reactive approach, both the workload and the service behaviour are completely
monitored and adequate thresholds are set on different metrics. When those thresholds are reached some
adapting actions are started.

\begin{figure}
	\centering{}
	\includegraphics[width=0.7\textwidth]{chapters/elasticity/images/adaptability.png}
	\caption[Different adaptability approaches]{The figure illustrate different adaptability approaches
		that a \ac{paas} vendor can adopt to manage the elasticity. If it chooses a reactive approach the
		system adapts themselves after the workload change happens; instead if it chooses a proactive approach
		it prefers to react close as possible to the workload change; finally if it chooses a predictive
		approach it attempts to predict future workload changes.}
	\label{img:elasticity-requirements-adaptability}
\end{figure}

In conclusion, proactive systems predict the forthcoming workload and apply any need reconfigurations
before hand. Instead, reactive systems monitor the current real workload and reconfigure themselves
when that current workload reaches a level that compromises their \ac{qos}.

\subsection{\acs{sla}-awareness}
\label{sec:elasticity-requirements-slaAwareness}
Cloud providers following any service model (including \ac{paas}) define a special kind of adaptive
system with autonomic behaviour, since the customer-provider relation is driven by a \ac{sla}.
\ac{sla}s partially set the goals to be achieved by a provider regarding service quality. The other
goals are related to its ``\ac{qobiz}''; i.e., those other goals deal with reducing service provisioning
costs in order to maximize the business benefit.

This induces a first differential factor between general autonomic computing systems and cloud computing
environments. All non-functions quality aspects might be included in a \ac{sla} and such \ac{sla} 
defines the quality-related objectives for those cloud providers. Besides those \glossarySng{slo}, a \ac{sla}
should also specify which are the penalties applied to a provider when those \ac{slo}s are not achieved
(assuming that clients satisfies its part of deal).

In the (ideal) \ac{paas} service model, cloud provider should manage \ac{sla}s with a rich set of objectives.
Thus \ac{paas} customers can select the most appropriate one for deploying and managing their applications
or services. The \ac{paas} service provider with the best relation between: available resource,
application-level performance guarantees and renting costs.

So, one of the existing challenges for \ac{paas} providers is to elastically manage the services being
deployed by multiple customers providing and guaranteeing a rich set of \ac{slo}s in their \ac{sla}s.

\subsection{Composability}
\label{sec:elasticity-requirements-composability}
As we argued in Section \ref{sec:elasticity-requirements-scalability}, the services being deployed in
\ac{paas} systems should be automatically scaled by the \ac{paas} itself. There are multiple approaches
to achieve this.

In the first place, those services should not be monolithic; if they were the scaling decisions would
be applied to the single element that implements that service. This would mean a lack of flexibility
when we try to improve such service performance, since we could only add, remove, redimension or migrate
instances of that single kind of element. Moreover, that single element would be larger than the regular
elements of a multi-component service and this would have complicated any scaling actions to be applied
onto it.

Instead, if the service is implemented by multiple small components, their scaling action will be faster
and cheaper, since the amount of resources needed to manage them will be also smaller.
Distributed services consist of multiple components that may be architected in layers. Such composability
makes possible that the proactive performance models consider the behaviour of each component. Therefore,
performance prediction model may be used to identify those components that are close to their saturation
point, applying then the most appropriate scaling actions on them. These components are replicated in
the regular case and define elements that are smaller than in monolithic designs.

Service composability has other implications too (shown in Figure \ref{img:elasticity-requirements-composability}).
It is able to provide reusable components that might have been already deployed among our \ac{paas} service provider
or among a third party one. Inter-service dependencies should be declared in the deployment descriptors and the
\ac{sla}s of those external services should be analysed in order to establish the \ac{sla} of such global service.
When those dependencies have been appropriately documented and are known by the scaling managers, any scaling
action on a given component will also raise appropriate complementary scaling actions in its dependant
component.

\begin{figure}
	\centering{}
	\includegraphics[width=0.75\textwidth]{chapters/elasticity/images/composability.png}
	\caption[Characterstics for service composability]{The figure illustrates the key characteristics that
		lead to service composability \cite{serviceComposability}.}
	\label{img:elasticity-requirements-composability}
\end{figure}

\subsection{Service continuity in software upgrades}
\label{sec:elasticity-requirements-serviceContinutiy}
Distributed services should guarantee their service continuity. This means that clients expect a
continuous availability. Real world software systems are never static. Clearly, software defects will
drive change. Additionally, market pressures and customer demands for new functionalities also drive
change, forcing service providers too continuously come up with newer version of the software that
runs their services. A careful software upgrading procedure should be designed taking into consideration
the term of the service's \ac{sla}, which in many cases will require some degree of service continuity
and availability.

\citeauthor{li2011evaluating} in \cite{li2011evaluating} provide a possible set of principles and mechanisms
that have to be considered in software upgrades taking into account defined \ac{sla}s. They must be followed
in the given sequence, and they are:

\begin{enumerate}
	\item{\keyword{global consistency}: the updating actions should be applied without aborting any started
		action; if some changes occur in the inter-communication protocol all involved parties should be
		appropriately upgrade with the new one;}
	\item{\keyword{service availability}: the overall service being upgraded should remain available
		in the updating interval. This means that it should be active and accepting requests;}
	\item{\keyword{coexistence and service continuity}: coexistence consists in maintaining active both
		software versions: the one being replaced and the new one that replaces it. Service continuity
		implies that every service request will not be ever blocked. Coexistence is a necessary condition
		for achieving service continuity;}
	\item{\keyword{state transfer}: the new software version may use a different state and such state will
		need a translation from previous version to the new one. Even in case of maintaining both version
		deployed in the same host, some kind physical copy might be needed;}
	\item{\keyword{minimal overhead}: there multiple managerial tasks in order to upgrade correctly the
		deployed software: new version deployment, old version removal, dynamic version management, etc.
		Those tasks should be executed on multiple nodes and thus should be carefully scheduled in order
		to minimize their effect on system performance.}
\end{enumerate}